{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Requirements"
      ],
      "metadata": {
        "id": "ZckYMoybbGYD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n45RTSAAi1m0",
        "outputId": "55a01c90-4a92-4c2f-e1b1-7ab7a886f9bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: razdel in /usr/local/lib/python3.7/dist-packages (0.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install razdel"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount colab"
      ],
      "metadata": {
        "id": "GFiMkUpBbROc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyMXb4UeoYHA",
        "outputId": "ed01a2bf-23f2-48c4-a0c0-fbe5de4732af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6Z_ZiCxEpMbb"
      },
      "outputs": [],
      "source": [
        "!mkdir models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-qMjb-MR29t"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import unicode_literals\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "from torch.jit import script, trace\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import csv\n",
        "import random\n",
        "import re\n",
        "import os\n",
        "import unicodedata\n",
        "import codecs\n",
        "from io import open\n",
        "import itertools\n",
        "import math\n",
        "from razdel import tokenize\n",
        "import gdown\n",
        "import pandas as pd\n",
        "import json\n",
        "import random\n",
        "import copy\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "0-BywF3ojQe7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdhiluNfSFug"
      },
      "source": [
        "# Download train data from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "k_bawuqbN3i9",
        "outputId": "eec3f197-3d62-4f65-8639-b9787054834d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1iFPkClVHzYC2werYdzIly38EOvP4HGFd\n",
            "To: /content/qa_data.json\n",
            "100%|██████████| 1.31G/1.31G [00:08<00:00, 153MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'qa_data.json'"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "gdown.download(url='https://drive.google.com/uc?id=1iFPkClVHzYC2werYdzIly38EOvP4HGFd', output='qa_data.json', quiet=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qX-wSjjSIXt"
      },
      "source": [
        "# Build functions for load data to memory and load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "n-7WeIt-SHqn"
      },
      "outputs": [],
      "source": [
        "def load_jsonl_data(path_to_jsonl: str) -> pd.DataFrame:\n",
        "    with open(path_to_jsonl) as f:\n",
        "        data = [json.loads(line) for line in f]\n",
        "    print(f'Loaded {len(data)} examples')\n",
        "    result_dict = {}\n",
        "    for i in range(len(data)):\n",
        "        result_dict[i] = data[i]\n",
        "    df = pd.DataFrame().from_dict(result_dict, orient='index')\n",
        "    del result_dict\n",
        "    del data\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Egse0g7TWCvD"
      },
      "outputs": [],
      "source": [
        "def filter_df_jsonl(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df['responses_len'] = df['responses'].apply(lambda x: len(x))\n",
        "    df['question_len'] = df['question'].apply(lambda x: len(x.split(' ')))\n",
        "    \n",
        "    df = df[(df['responses_len'] >= 2)&(df['question_len'] >= 10)]\n",
        "\n",
        "    del df['question_len']\n",
        "    del df['responses_len']\n",
        "\n",
        "    def select_max_response(responses: list) -> str:\n",
        "        max_len = 0\n",
        "        index_for_return = None\n",
        "        for i in range(len(responses)):\n",
        "            if len(responses[i]) > max_len:\n",
        "                max_len = len(responses[i])\n",
        "                index_for_return = copy.copy(i)\n",
        "        \n",
        "        return responses[index_for_return]\n",
        "    \n",
        "    df['responses'] = df['responses'].apply(select_max_response)\n",
        "    \n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYGSKeIDOfEm",
        "outputId": "4c1139b2-fa5c-463a-9a7e-4b9cf079e291"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 2808811 examples\n"
          ]
        }
      ],
      "source": [
        "df = load_jsonl_data('qa_data.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jb0iVoJY08Y",
        "outputId": "a684d958-577b-4132-9268-420446b931f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2808811\n"
          ]
        }
      ],
      "source": [
        "print(len(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vu35aSvpQitK",
        "outputId": "5ee85a86-2bc5-4881-d82b-e00c19c67ed6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ],
      "source": [
        "df_filtred = filter_df_jsonl(df)\n",
        "del df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "mAJdTbB1TQZv",
        "outputId": "fa6a51a6-0f5c-4166-f611-3339194370c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1daa46fa-e734-4e41-8a10-cca73a9c49ec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>category</th>\n",
              "      <th>responses</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2808782</th>\n",
              "      <td>как пользоваьбся шпорой, куда ее сувать если з...</td>\n",
              "      <td>Образование</td>\n",
              "      <td>пиши на линейке... деревянной.. карандашом.. в...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2808783</th>\n",
              "      <td>хочу приобрести крысу , но у меня аллергия , м...</td>\n",
              "      <td>Животные, Растения</td>\n",
              "      <td>вот лысая:      но не думаю что у вас алергия ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2808785</th>\n",
              "      <td>как называется песня я только помню что она бы...</td>\n",
              "      <td>Искусство и Культура</td>\n",
              "      <td>new world sound &amp;amp; thomas newson — flute  j...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2808788</th>\n",
              "      <td>*** почему ...многие не признаются, что у них ...</td>\n",
              "      <td>Знакомства, Любовь, Отношения</td>\n",
              "      <td>ну я лично понимаю, что настроил себе иллюзий....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2808790</th>\n",
              "      <td>удар если удар составляет 500 кг. при росте 18...</td>\n",
              "      <td>Спорт</td>\n",
              "      <td>смотря чем? если кувалдой кг на 20, то да, а е...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2808795</th>\n",
              "      <td>вас жестоко передавали те, кому вы верили? и ч...</td>\n",
              "      <td>Знакомства, Любовь, Отношения</td>\n",
              "      <td>сделала и сделала. главное, что чел этого не з...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2808797</th>\n",
              "      <td>в каком месте колоть язык?? ? главное в вены н...</td>\n",
              "      <td>Красота и Здоровье</td>\n",
              "      <td>идиотизм, а если потеряете дар речи, повредив ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2808798</th>\n",
              "      <td>можно ли завести рыбок гуппи, если у тебя алле...</td>\n",
              "      <td>Животные, Растения</td>\n",
              "      <td>вообще гуппи едят корм но раз аллергия можно д...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2808802</th>\n",
              "      <td>можно ли использовать реплику чатского \"а судь...</td>\n",
              "      <td>Искусство и Культура</td>\n",
              "      <td>можно. там у островского, насколько помню, одн...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2808810</th>\n",
              "      <td>какой вам начальник больше подойдёт?глупый - н...</td>\n",
              "      <td>Работа, Карьера</td>\n",
              "      <td>глупому начальнику можно что угодно \"втереть\",...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1daa46fa-e734-4e41-8a10-cca73a9c49ec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1daa46fa-e734-4e41-8a10-cca73a9c49ec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1daa46fa-e734-4e41-8a10-cca73a9c49ec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                  question  ...                                          responses\n",
              "2808782  как пользоваьбся шпорой, куда ее сувать если з...  ...  пиши на линейке... деревянной.. карандашом.. в...\n",
              "2808783  хочу приобрести крысу , но у меня аллергия , м...  ...  вот лысая:      но не думаю что у вас алергия ...\n",
              "2808785  как называется песня я только помню что она бы...  ...  new world sound &amp; thomas newson — flute  j...\n",
              "2808788  *** почему ...многие не признаются, что у них ...  ...  ну я лично понимаю, что настроил себе иллюзий....\n",
              "2808790  удар если удар составляет 500 кг. при росте 18...  ...  смотря чем? если кувалдой кг на 20, то да, а е...\n",
              "2808795  вас жестоко передавали те, кому вы верили? и ч...  ...  сделала и сделала. главное, что чел этого не з...\n",
              "2808797  в каком месте колоть язык?? ? главное в вены н...  ...  идиотизм, а если потеряете дар речи, повредив ...\n",
              "2808798  можно ли завести рыбок гуппи, если у тебя алле...  ...  вообще гуппи едят корм но раз аллергия можно д...\n",
              "2808802  можно ли использовать реплику чатского \"а судь...  ...  можно. там у островского, насколько помню, одн...\n",
              "2808810  какой вам начальник больше подойдёт?глупый - н...  ...  глупому начальнику можно что угодно \"втереть\",...\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df_filtred.tail(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AH_RoVFUZ_lu",
        "outputId": "3510ca12-5a7c-4f74-9ee9-3bd0fc448018"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "841064"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len(df_filtred)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Выбираем небольшой набор данных случайным образом чтобы проверить что модель обучается\n",
        "df_filtred = df_filtred.sample(10000)"
      ],
      "metadata": {
        "id": "c--Q2OWOmkJ1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FU1ksld0jSCr"
      },
      "outputs": [],
      "source": [
        "def preprocessing_sentence(sentence: str) -> list:\n",
        "    s = sentence.lower().strip()\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^0-9a-zA-Zа-яёА-ЯЁ]+\", r\" \", s)\n",
        "    tokens = list(tokenize(s))\n",
        "    res_sent = [_.text for _ in tokens]\n",
        "    return res_sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "AajD21WNkAnZ"
      },
      "outputs": [],
      "source": [
        "questions = df_filtred['question'].apply(preprocessing_sentence).tolist()\n",
        "responses = df_filtred['responses'].apply(preprocessing_sentence).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikmOZxntlJN-",
        "outputId": "b6164d34-252c-4535-8232-c28c152a5011"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['зачем',\n",
              " 'парни',\n",
              " 'так',\n",
              " 'делают',\n",
              " 'когда',\n",
              " 'обнимаюсь',\n",
              " 'или',\n",
              " 'целуюсь',\n",
              " 'с',\n",
              " 'парнем',\n",
              " 'он',\n",
              " 'берет',\n",
              " 'меня',\n",
              " 'за',\n",
              " 'бедра',\n",
              " 'и',\n",
              " 'прижимает',\n",
              " 'к',\n",
              " 'себе']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "questions[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amA-dIvBmG04",
        "outputId": "5571c38f-8df9-4737-d347-4179a2ef2a9e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['укусит',\n",
              " 'за',\n",
              " 'шею',\n",
              " 'попьёт',\n",
              " 'твоей',\n",
              " 'крови',\n",
              " 'и',\n",
              " 'потом',\n",
              " 'ты',\n",
              " 'сама',\n",
              " 'станешь',\n",
              " 'такой',\n",
              " 'видишь',\n",
              " 'тут',\n",
              " 'многих',\n",
              " 'бараны',\n",
              " 'покусали']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "responses[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "lvnpecKmliph"
      },
      "outputs": [],
      "source": [
        "max_len_all = 0\n",
        "for sen in questions:\n",
        "    if len(sen) > max_len_all:\n",
        "        max_len_all = len(sen)\n",
        "\n",
        "for sen in responses:\n",
        "    if len(sen) > max_len_all:\n",
        "        max_len_all = len(sen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9F0U5Fnlw5M",
        "outputId": "201b0984-dee1-4a05-b4b5-36b72bbfcbf8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "max_len_all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "uv6SRrpMfa6p"
      },
      "outputs": [],
      "source": [
        "max_length = 60\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model_name = 'myseq2seq'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ZLSjIeAxa8Nv"
      },
      "outputs": [],
      "source": [
        "pad_token = 0\n",
        "sos_token = 1\n",
        "eos_token = 2\n",
        "\n",
        "class Voc:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.trimmed = False\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {pad_token:'PAD', sos_token:'SOS', eos_token : 'EOS'}\n",
        "        self.numword = 3\n",
        "        \n",
        "    def add_sentence(self, sentence):\n",
        "        s = sentence.lower().strip()\n",
        "        s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "        s = re.sub(r\"[^0-9a-zA-Zа-яёА-ЯЁ]+\", r\" \", s)\n",
        "        tokens = list(tokenize(s))\n",
        "        res_sent = [_.text for _ in tokens]\n",
        "        for word in res_sent:\n",
        "            self.addword(word)\n",
        "            \n",
        "    def addword(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.numword\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.numword] = word\n",
        "            self.numword += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "voc = Voc(model_name)\n",
        "\n",
        "for sent in questions:\n",
        "    for word in sent:\n",
        "        voc.addword(word)\n",
        "\n",
        "for sent in responses:\n",
        "    for word in sent:\n",
        "        voc.addword(word)\n",
        "\n",
        "pairs = list(zip(questions, responses))\n",
        "\n",
        "voc, trimmed_pair =  voc, pairs"
      ],
      "metadata": {
        "id": "P3MrnRlPhbMD"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trimmed_pair[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGPuc-42ix8L",
        "outputId": "6b307c90-efc6-46cd-ae13-4dba2833c1e3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['зачем',\n",
              "  'парни',\n",
              "  'так',\n",
              "  'делают',\n",
              "  'когда',\n",
              "  'обнимаюсь',\n",
              "  'или',\n",
              "  'целуюсь',\n",
              "  'с',\n",
              "  'парнем',\n",
              "  'он',\n",
              "  'берет',\n",
              "  'меня',\n",
              "  'за',\n",
              "  'бедра',\n",
              "  'и',\n",
              "  'прижимает',\n",
              "  'к',\n",
              "  'себе'],\n",
              " ['укусит',\n",
              "  'за',\n",
              "  'шею',\n",
              "  'попьёт',\n",
              "  'твоей',\n",
              "  'крови',\n",
              "  'и',\n",
              "  'потом',\n",
              "  'ты',\n",
              "  'сама',\n",
              "  'станешь',\n",
              "  'такой',\n",
              "  'видишь',\n",
              "  'тут',\n",
              "  'многих',\n",
              "  'бараны',\n",
              "  'покусали'])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def index_from_sentence(voc, sentence):\n",
        "    return [voc.word2index[word] for word in sentence] + [eos_token]"
      ],
      "metadata": {
        "id": "W3R4ryeNhBIh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def zeroPadding(l,fillvalue=pad_token):\n",
        "    return list(itertools.zip_longest(*l, fillvalue = fillvalue))\n",
        "\n",
        "def binaryMatrix(l, value=pad_token):\n",
        "    m = []\n",
        "    for i, seq in enumerate(l):\n",
        "        m.append([])\n",
        "        for token in seq:\n",
        "            if token == pad_token:\n",
        "                m[i].append(0)\n",
        "            else:\n",
        "                m[i].append(1)\n",
        "    return m\n",
        "\n",
        "def input_to_torch(l, voc):\n",
        "    indexes_batch = [index_from_sentence(voc, sentence) for sentence in l]\n",
        "    padded_list_index = zeroPadding(indexes_batch)\n",
        "    padded_tensor_index = torch.LongTensor(padded_list_index)\n",
        "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
        "    return padded_tensor_index, lengths"
      ],
      "metadata": {
        "id": "xBRbIOwZhTih"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def output_to_torch(l, voc):\n",
        "    indexes_batch = [index_from_sentence(voc, sentence) for sentence in l]\n",
        "    padded_list_index = zeroPadding(indexes_batch)\n",
        "    padded_tensor_index = torch.LongTensor(padded_list_index)\n",
        "    max_output_length = max([len(indexes) for indexes in indexes_batch])\n",
        "    mask = binaryMatrix(padded_list_index)\n",
        "    mask = torch.ByteTensor(mask)\n",
        "    return padded_tensor_index, mask, max_output_length"
      ],
      "metadata": {
        "id": "cHqlacSChWVp"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch_pair(voc, batch_pair):\n",
        "    batch_pair.sort(key = lambda x: len(x[0]), reverse = True )\n",
        "    input_batch, response_batch = [], []\n",
        "    for pair in batch_pair:\n",
        "        input_batch.append(pair[0])\n",
        "        response_batch.append(pair[1])\n",
        "    \n",
        "    input_tensor, length_input = input_to_torch(input_batch, voc)\n",
        "    output_tensor, mask, max_length = output_to_torch(response_batch, voc)\n",
        "    return input_tensor, length_input, output_tensor, mask, max_length"
      ],
      "metadata": {
        "id": "6KLEc-7yhYBm"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, embedding, hidden_size, num_layers = 1,dropout = 0):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = embedding\n",
        "        self.hidden_size = hidden_size\n",
        "        self.gru = nn.GRU(  input_size = hidden_size\n",
        "                          , hidden_size = hidden_size\n",
        "                          , num_layers = num_layers\n",
        "                          , dropout = (0 if num_layers == 1 else dropout)\n",
        "                          , bidirectional = True)\n",
        "    def forward(self, input_seq, input_length, hidden = None):\n",
        "        embedding = self.embedding(input_seq)\n",
        "        packed_input = torch.nn.utils.rnn.pack_padded_sequence(embedding, input_length)\n",
        "        output, hidden_cell = self.gru(packed_input, hidden)\n",
        "        output, _ = torch.nn.utils.rnn.pad_packed_sequence(output)\n",
        "        output = output[:,:,:self.hidden_size] + output[:,:,self.hidden_size:]\n",
        "        return output, hidden_cell\n",
        "    "
      ],
      "metadata": {
        "id": "a9JU6iz8hZen"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionLayer(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(AttentionLayer, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.attn = torch.nn.Linear(self.hidden_size * 2, hidden_size)\n",
        "        self.weight = nn.Parameter(torch.FloatTensor(hidden_size))\n",
        "            \n",
        "    def get_dot_score(self, hidden, encoder_outputs):\n",
        "        return torch.sum(hidden*encoder_outputs, dim=2)\n",
        "    \n",
        "    def get_general_score(self, hidden, encoder_outputs):\n",
        "        energy = self.attn(encoder_outputs)\n",
        "        return torch.sum(hidden * energy, dim=2)\n",
        "    \n",
        "    def get_concat_score(self, hidden, encoder_outputs):\n",
        "        concat = torch.cat((hidden.expand(encoder_outputs.size(0),-1,-1), encoder_outputs), dim=2)\n",
        "        energy = torch.tanh(self.attn(concat))\n",
        "        return torch.sum(self.weight * energy, dim=2)\n",
        "                           \n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        attn_energy = self.get_concat_score(hidden, encoder_outputs)\n",
        "        attn_energy = attn_energy.t()\n",
        "        return F.softmax(attn_energy, dim=1).unsqueeze(1)"
      ],
      "metadata": {
        "id": "IvpW3uNgjCP1"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionDecoder(nn.Module):\n",
        "    def __init__(self, embedding, hidden_size, output_size, n_layers=1, dropout = 0.1):\n",
        "        super(AttentionDecoder, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "        \n",
        "        self.embedding = embedding\n",
        "        self.embedding_dropout = nn.Dropout(dropout)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n",
        "\n",
        "        self.concat = nn.Linear(hidden_size*2, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.attention = AttentionLayer(hidden_size)\n",
        "        \n",
        "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input_step)\n",
        "        embedded = self.embedding_dropout(embedded)\n",
        "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
        "        attention_weights = self.attention(rnn_output, encoder_outputs)\n",
        "        context = attention_weights.bmm(encoder_outputs.transpose(0,1))\n",
        "        rnn_output = rnn_output.squeeze(0)\n",
        "        context = context.squeeze(1)\n",
        "        concat_input =  torch.cat((rnn_output, context), 1)\n",
        "        concat_output = torch.tanh(self.concat(concat_input))\n",
        "        output = self.out(concat_output)\n",
        "        output = F.softmax(output, dim=1)\n",
        "        return output, hidden"
      ],
      "metadata": {
        "id": "bT1PPe8UjEG8"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def maskNLLLoss(input, target, mask):\n",
        "    nTotal = mask.sum()\n",
        "    crossEntropy = -torch.log(torch.gather(input, 1, target.view(-1, 1)).squeeze(1))\n",
        "    loss = crossEntropy.masked_select(mask).mean()\n",
        "    loss = loss.to(device)\n",
        "    return loss, nTotal.item()"
      ],
      "metadata": {
        "id": "6z4DPyodjGNx"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "def train(input_variable, lengths, target_variable, embedding, encoder, decoder, encoder_optimizer, decoder_optimizer, max_target_lens\n",
        "            , batch_size, clip, mask,max_length = max_length):\n",
        "    \n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_variable = input_variable.to(device)\n",
        "    target_variable = target_variable.to(device)\n",
        "\n",
        "    mask = mask.bool()\n",
        "    mask = mask.to(device)\n",
        "\n",
        "    loss = 0\n",
        "    print_loss = []\n",
        "    n_totals = 0\n",
        "\n",
        "    output_encoders,  hidden_encoders = encoder(input_variable, lengths)\n",
        "\n",
        "    input_decoders = torch.LongTensor([[sos_token for _ in range(batch_size)]])\n",
        "    input_decoders = input_decoders.to(device)\n",
        "\n",
        "    hidden_decoders = hidden_encoders[:decoder.n_layers]\n",
        "    teacher_forcing = True if random.random() < teacher_forcing_rate else False\n",
        "    \n",
        "\n",
        "    if teacher_forcing:\n",
        "        for t in range(max_target_lens):\n",
        "            output_decoders, hidden_decoders = decoder(input_decoders, hidden_decoders, output_encoders)\n",
        "            input_decoders = target_variable[t].view(1, -1)\n",
        "            mask_loss, nTotal = maskNLLLoss(output_decoders, target_variable[t], mask[t])\n",
        "            loss+=mask_loss\n",
        "            print_loss.append(mask_loss.item() * nTotal)\n",
        "            n_totals += nTotal\n",
        "    else:\n",
        "        for t in range(max_target_lens):\n",
        "            output_decoders, hidden_encoders = decoder(input_decoders, hidden_decoders, output_encoders)\n",
        "            _, topi = output_decoders.topk(1)\n",
        "            input_decoders = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
        "            input_decoders = input_decoders.to(device)\n",
        "            mask_loss, nTotal = maskNLLLoss(output_decoders, target_variable[t], mask[t])\n",
        "            loss += mask_loss\n",
        "            print_loss.append(mask_loss.item() * nTotal)\n",
        "            n_totals += nTotal\n",
        "    loss.backward()\n",
        "    _ = torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
        "    _ = torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "    return sum(print_loss) / n_totals\n",
        "    "
      ],
      "metadata": {
        "id": "jhhmA97RjIeN"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainIters(model_name, voc, trimmed_pair, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers,\n",
        "               decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name,):\n",
        "    training_batches = [get_batch_pair(voc, [random.choice(trimmed_pair) for _ in range(batch_size)]) for _ in range(n_iteration)]\n",
        "    print('initializing...')\n",
        "    start_iteration = 1\n",
        "    print_loss = 0\n",
        "    \n",
        "    print('Tranining...')\n",
        "    for iteration in range(start_iteration, n_iteration +1):\n",
        "        training_batch = training_batches[iteration-1]\n",
        "        input_variable, lengths, target_variable, mask, max_target_lens = training_batch\n",
        "        loss = train(input_variable, lengths, target_variable, embedding, encoder, decoder, encoder_optimizer, decoder_optimizer, max_target_lens\n",
        "            , batch_size, clip, mask)\n",
        "        print_loss += loss\n",
        "        if (iteration % print_every) == 0:\n",
        "            print_loss_avg = print_loss / print_every\n",
        "            print(f'loss_avg at {iteration} is: {print_loss_avg}, in {100 * iteration / n_iteration } % progress complete')\n",
        "            print_loss = 0\n",
        "        if (iteration % save_every) == 0:\n",
        "           directory = os.path.join(path_save, model_name, corpus_name, f'{encoder_n_layers}-{decoder_n_layers}_{hidden_size}')\n",
        "           if not os.path.exists(directory):\n",
        "               os.makedirs(directory)\n",
        "           torch.save({\n",
        "               'iteration': iteration,\n",
        "               'encoder' : encoder.state_dict(),\n",
        "               'decoder' : decoder.state_dict(),\n",
        "               'encoder_optimizer': encoder_optimizer.state_dict(),\n",
        "               'decoder_optimizer': decoder_optimizer.state_dict(),\n",
        "               'loss' : loss,\n",
        "               'voc_dict'  : voc.__dict__,\n",
        "               'embedding': embedding.state_dict()\n",
        "            }, os.path.join(directory, '{}_{}.tar'.format(iteration, 'checkpoint')))            "
      ],
      "metadata": {
        "id": "Fu4c9ARmjSpm"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Greedysearch_decoder(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(Greedysearch_decoder, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "    \n",
        "    def forward(self, input_seq, input_length, max_length):\n",
        "        output_encoder, hidden_encoder = self.encoder(input_seq, input_length)\n",
        "        hidden_decoder = hidden_encoder[:decoder.n_layers]\n",
        "        input_decoder = torch.ones(1,1,device = device, dtype = torch.long) * sos_token\n",
        "        all_tokens = torch.zeros([0], device=device, dtype = torch.long)\n",
        "        all_score  = torch.zeros([0], device=device)\n",
        "        for _ in range(max_length):\n",
        "            output_decoder, hidden_decoder = self.decoder(input_decoder, hidden_decoder, output_encoder)\n",
        "            max_score, output_index = torch.max(output_decoder, dim = 1)\n",
        "            all_tokens = torch.cat((all_tokens, output_index), dim = 0)\n",
        "            all_score = torch.cat((all_score, max_score), dim = 0)\n",
        "            input_decoder = torch.unsqueeze(output_index, 0)\n",
        "        return all_tokens, all_score"
      ],
      "metadata": {
        "id": "iBXuZyvujnnd"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(encoder, decoder, searcher, voc, sentence, max_length = max_length):\n",
        "    index_sentence_list = [index_from_sentence(voc, sentence)]\n",
        "    input_lengths = torch.tensor([len(index) for index in index_sentence_list])\n",
        "    index_sentence = torch.LongTensor(index_sentence_list)\n",
        "    input_batch = index_sentence.transpose(0,1)\n",
        "    input_batch = input_batch.to(device)\n",
        "    output_tokens, output_scores = searcher(input_batch, input_lengths, max_length) \n",
        "    words_decoder = [voc.index2word[index.item()] for index in output_tokens]\n",
        "    return words_decoder\n",
        "\n",
        "\n",
        "def predict_answer(encoder, decoder, search, voc, input_sentence):\n",
        "    input_sentence = preprocessing_sentence(input_sentence)\n",
        "    res_input_sentence = list()\n",
        "    for word in input_sentence:\n",
        "        if word in voc.word2index:\n",
        "            res_input_sentence.append(word)\n",
        "    words_decoder = evaluate(encoder, decoder, search, voc, res_input_sentence)\n",
        "    words_decoder[:]  = [word for word in words_decoder if word not in ['PAD','EOS']]\n",
        "    print(' '.join(words_decoder))"
      ],
      "metadata": {
        "id": "FVM0QwzUjqWT"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 512\n",
        "encoder_n_layers = 3\n",
        "decoder_n_layers = 3\n",
        "dropout = 0.1\n",
        "batch_size = 64\n",
        "checkpoint_iter = 10000"
      ],
      "metadata": {
        "id": "X3XQ3s-hjsci"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = nn.Embedding(voc.numword, hidden_size)\n",
        "encoder = EncoderRNN(embedding, hidden_size, encoder_n_layers, dropout)\n",
        "decoder = AttentionDecoder(embedding, hidden_size, voc.numword, decoder_n_layers, dropout)\n",
        "encoder = encoder.to(device)\n",
        "decoder = decoder.to(device)"
      ],
      "metadata": {
        "id": "5Fj597ESj4RZ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "QRj7NPV_lsfM",
        "outputId": "7962c22b-f249-4c0b-ad69-b1d6960e882f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clip = 50.0\n",
        "teacher_forcing_rate = 1.0\n",
        "learning_rate = 3e-4\n",
        "decoder_learning_rate = 5.0\n",
        "n_iteration = 10000\n",
        "print_every = 1000\n",
        "save_every = 5000\n",
        "path_save = './models/'\n",
        "\n",
        "encoder.train()\n",
        "decoder.train()\n",
        "\n",
        "print('Building optimizers ...')\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_rate)\n",
        "\n",
        "print(\"Starting Training!\")\n",
        "trainIters(model_name, voc, trimmed_pair, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
        "           embedding, encoder_n_layers, decoder_n_layers, path_save, n_iteration, batch_size,\n",
        "           print_every, save_every, clip, model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3fwgephkCft",
        "outputId": "14c43092-9b86-4892-ca7c-8a6a60add55e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building optimizers ...\n",
            "Starting Training!\n",
            "initializing...\n",
            "Tranining...\n",
            "loss_avg at 1000 is: 6.710489610945203, in 10.0 % progress complete\n",
            "loss_avg at 2000 is: 3.949417522309355, in 20.0 % progress complete\n",
            "loss_avg at 3000 is: 2.3891349722606465, in 30.0 % progress complete\n",
            "loss_avg at 4000 is: 1.4062898633463614, in 40.0 % progress complete\n",
            "loss_avg at 5000 is: 0.8255642938884654, in 50.0 % progress complete\n",
            "loss_avg at 6000 is: 0.5283654809083402, in 60.0 % progress complete\n",
            "loss_avg at 7000 is: 0.41006448695574993, in 70.0 % progress complete\n",
            "loss_avg at 8000 is: 0.2963281483093786, in 80.0 % progress complete\n",
            "loss_avg at 9000 is: 0.23319580083737337, in 90.0 % progress complete\n",
            "loss_avg at 10000 is: 0.276209027614968, in 100.0 % progress complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"./models/myseq2seq/myseq2seq/3-3_512/10000_checkpoint.tar\" \"/content/drive/MyDrive/10000_checkpoint_3_3_512.tar\""
      ],
      "metadata": {
        "id": "hrAFf_1bWAUv"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub_smp = df_filtred.sample(5)\n",
        "sent_q = sub_smp['question'].tolist()\n",
        "sent_a = sub_smp['responses'].tolist()"
      ],
      "metadata": {
        "id": "29GLT0GCwZUM"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.eval()\n",
        "decoder.eval()\n",
        "\n",
        "searcher = Greedysearch_decoder(encoder, decoder)\n",
        "\n",
        "for i in range(len(sent_q)):\n",
        "    print('Вопрос', sent_q[i])\n",
        "    print('Ответ')\n",
        "    predict_answer(encoder, decoder, searcher, voc, sent_q[i])\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zp6AAQcpw6Vj",
        "outputId": "2f87f6bc-1bb5-4058-b970-818cc3481497"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вопрос а вы бы завели лошадь???конечно если бы били условия и деньги.\n",
            "Ответ\n",
            "канеш очень красивое и умное животное я бы на ней на рыбалку и охоту гонял\n",
            "\n",
            "Вопрос какой немецкий игрок в матче с португалией забил гол, сделал пару голевых передач и стал героем дня?\n",
            "Ответ\n",
            "швайни я думаю лучшим игроком фильмы лучшим игроком матча игроком матча лучшим игроком матча михаэля баллака игроком матча я игроком\n",
            "\n",
            "Вопрос если в описании дивана еврокнижки сказано \"требует сборки\" это в каком виде он приходит? как две половинки или как?\n",
            "Ответ\n",
            "вопрос некорректен смотря у кого покупаете неужели так сложно выясни все вопросы у продавца\n",
            "\n",
            "Вопрос кто-то все же разбудил спящую собаку))) но!! это к лучшему)) а у вас что к лучшему!?)) если не секрет))\n",
            "Ответ\n",
            "у меня нет собаки а у вас видать проблемы воры пробрались через окно и это муж ваш его разбудил\n",
            "\n",
            "Вопрос сегодня резко во время движения руль стал очень тугим. остановился, выключил, включил. больше не повторялось.\n",
            "Ответ\n",
            "гур проверь может уровень масла низкий а может и менять пора пора сих\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nfZRAAtxTWEG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "deeplearning_finalproject.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}