{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZckYMoybbGYD"
      },
      "source": [
        "# Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n45RTSAAi1m0",
        "outputId": "9ef14975-4198-4380-b8c9-1ac0f55a4460"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting razdel\n",
            "  Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: razdel\n",
            "Successfully installed razdel-0.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install razdel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFiMkUpBbROc"
      },
      "source": [
        "# Mount colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyMXb4UeoYHA",
        "outputId": "62d3b11f-6f90-493f-f5b7-e11a682bfaf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6Z_ZiCxEpMbb"
      },
      "outputs": [],
      "source": [
        "!mkdir models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-qMjb-MR29t"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0-BywF3ojQe7"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import unicode_literals\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "from torch.jit import script, trace\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import csv\n",
        "import random\n",
        "import re\n",
        "import os\n",
        "import unicodedata\n",
        "import codecs\n",
        "from io import open\n",
        "import itertools\n",
        "import math\n",
        "from razdel import tokenize\n",
        "import gdown\n",
        "import pandas as pd\n",
        "import json\n",
        "import random\n",
        "import copy\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdhiluNfSFug"
      },
      "source": [
        "# Download train data from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "k_bawuqbN3i9",
        "outputId": "b565f86d-1848-434b-fbe5-0e2b6874aa49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1iFPkClVHzYC2werYdzIly38EOvP4HGFd\n",
            "To: /content/qa_data.json\n",
            "100%|██████████| 1.31G/1.31G [00:05<00:00, 254MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'qa_data.json'"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "gdown.download(url='https://drive.google.com/uc?id=1iFPkClVHzYC2werYdzIly38EOvP4HGFd', output='qa_data.json', quiet=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qX-wSjjSIXt"
      },
      "source": [
        "# Build functions for load data to memory and load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "n-7WeIt-SHqn"
      },
      "outputs": [],
      "source": [
        "def load_jsonl_data(path_to_jsonl: str) -> pd.DataFrame:\n",
        "    with open(path_to_jsonl) as f:\n",
        "        data = [json.loads(line) for line in f]\n",
        "    print(f'Loaded {len(data)} examples')\n",
        "    result_dict = {}\n",
        "    for i in range(len(data)):\n",
        "        result_dict[i] = data[i]\n",
        "    df = pd.DataFrame().from_dict(result_dict, orient='index')\n",
        "    del result_dict\n",
        "    del data\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Egse0g7TWCvD"
      },
      "outputs": [],
      "source": [
        "def filter_df_jsonl(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df['responses_len'] = df['responses'].apply(lambda x: len(x))\n",
        "    df['question_len'] = df['question'].apply(lambda x: len(x.split(' ')))\n",
        "    \n",
        "    df = df[(df['responses_len'] >= 2)&(df['question_len'] >= 10)]\n",
        "\n",
        "    del df['question_len']\n",
        "    del df['responses_len']\n",
        "\n",
        "    def select_max_response(responses: list) -> str:\n",
        "        max_len = 0\n",
        "        index_for_return = None\n",
        "        for i in range(len(responses)):\n",
        "            if len(responses[i]) > max_len:\n",
        "                max_len = len(responses[i])\n",
        "                index_for_return = copy.copy(i)\n",
        "        \n",
        "        return responses[index_for_return]\n",
        "    \n",
        "    df['responses'] = df['responses'].apply(select_max_response)\n",
        "    \n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYGSKeIDOfEm",
        "outputId": "c395f695-51be-4e64-e251-00c448897402"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 2808811 examples\n"
          ]
        }
      ],
      "source": [
        "df = load_jsonl_data('qa_data.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jb0iVoJY08Y",
        "outputId": "01c0b256-5b11-49eb-b6b9-736f1e8b1a85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2808811\n"
          ]
        }
      ],
      "source": [
        "print(len(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vu35aSvpQitK",
        "outputId": "a6196f99-d537-4ed0-a9fe-d1b6c0bbf084"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ],
      "source": [
        "df_filtred = filter_df_jsonl(df)\n",
        "del df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "mAJdTbB1TQZv",
        "outputId": "7f0ae1b5-ffcd-41ee-8c14-68eab2e9136e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2cf26022-c98a-4f66-bddc-d873c8e6cac9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>category</th>\n",
              "      <th>responses</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2808782</th>\n",
              "      <td>как пользоваьбся шпорой, куда ее сувать если з...</td>\n",
              "      <td>Образование</td>\n",
              "      <td>пиши на линейке... деревянной.. карандашом.. в...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2808783</th>\n",
              "      <td>хочу приобрести крысу , но у меня аллергия , м...</td>\n",
              "      <td>Животные, Растения</td>\n",
              "      <td>вот лысая:      но не думаю что у вас алергия ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2808785</th>\n",
              "      <td>как называется песня я только помню что она бы...</td>\n",
              "      <td>Искусство и Культура</td>\n",
              "      <td>new world sound &amp;amp; thomas newson — flute  j...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2808788</th>\n",
              "      <td>*** почему ...многие не признаются, что у них ...</td>\n",
              "      <td>Знакомства, Любовь, Отношения</td>\n",
              "      <td>ну я лично понимаю, что настроил себе иллюзий....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2808790</th>\n",
              "      <td>удар если удар составляет 500 кг. при росте 18...</td>\n",
              "      <td>Спорт</td>\n",
              "      <td>смотря чем? если кувалдой кг на 20, то да, а е...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2808795</th>\n",
              "      <td>вас жестоко передавали те, кому вы верили? и ч...</td>\n",
              "      <td>Знакомства, Любовь, Отношения</td>\n",
              "      <td>сделала и сделала. главное, что чел этого не з...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2808797</th>\n",
              "      <td>в каком месте колоть язык?? ? главное в вены н...</td>\n",
              "      <td>Красота и Здоровье</td>\n",
              "      <td>идиотизм, а если потеряете дар речи, повредив ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2808798</th>\n",
              "      <td>можно ли завести рыбок гуппи, если у тебя алле...</td>\n",
              "      <td>Животные, Растения</td>\n",
              "      <td>вообще гуппи едят корм но раз аллергия можно д...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2808802</th>\n",
              "      <td>можно ли использовать реплику чатского \"а судь...</td>\n",
              "      <td>Искусство и Культура</td>\n",
              "      <td>можно. там у островского, насколько помню, одн...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2808810</th>\n",
              "      <td>какой вам начальник больше подойдёт?глупый - н...</td>\n",
              "      <td>Работа, Карьера</td>\n",
              "      <td>глупому начальнику можно что угодно \"втереть\",...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2cf26022-c98a-4f66-bddc-d873c8e6cac9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2cf26022-c98a-4f66-bddc-d873c8e6cac9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2cf26022-c98a-4f66-bddc-d873c8e6cac9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                  question  ...                                          responses\n",
              "2808782  как пользоваьбся шпорой, куда ее сувать если з...  ...  пиши на линейке... деревянной.. карандашом.. в...\n",
              "2808783  хочу приобрести крысу , но у меня аллергия , м...  ...  вот лысая:      но не думаю что у вас алергия ...\n",
              "2808785  как называется песня я только помню что она бы...  ...  new world sound &amp; thomas newson — flute  j...\n",
              "2808788  *** почему ...многие не признаются, что у них ...  ...  ну я лично понимаю, что настроил себе иллюзий....\n",
              "2808790  удар если удар составляет 500 кг. при росте 18...  ...  смотря чем? если кувалдой кг на 20, то да, а е...\n",
              "2808795  вас жестоко передавали те, кому вы верили? и ч...  ...  сделала и сделала. главное, что чел этого не з...\n",
              "2808797  в каком месте колоть язык?? ? главное в вены н...  ...  идиотизм, а если потеряете дар речи, повредив ...\n",
              "2808798  можно ли завести рыбок гуппи, если у тебя алле...  ...  вообще гуппи едят корм но раз аллергия можно д...\n",
              "2808802  можно ли использовать реплику чатского \"а судь...  ...  можно. там у островского, насколько помню, одн...\n",
              "2808810  какой вам начальник больше подойдёт?глупый - н...  ...  глупому начальнику можно что угодно \"втереть\",...\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "df_filtred.tail(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AH_RoVFUZ_lu",
        "outputId": "a264b80f-7627-43c3-c9da-38c075f3022d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "841064"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "len(df_filtred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "c--Q2OWOmkJ1"
      },
      "outputs": [],
      "source": [
        "# Выбираем небольшой набор данных случайным образом чтобы проверить что модель обучается\n",
        "df_filtred = df_filtred.sample(10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "FU1ksld0jSCr"
      },
      "outputs": [],
      "source": [
        "def preprocessing_sentence(sentence: str) -> list:\n",
        "    s = sentence.lower().strip()\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^0-9a-zA-Zа-яёА-ЯЁ]+\", r\" \", s)\n",
        "    tokens = list(tokenize(s))\n",
        "    res_sent = [_.text for _ in tokens]\n",
        "    return res_sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "xj9eUkAtNcID"
      },
      "outputs": [],
      "source": [
        "questions = df_filtred['question'].apply(preprocessing_sentence).tolist()\n",
        "responses = df_filtred['responses'].apply(preprocessing_sentence).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "49R7IN6cMRmL"
      },
      "outputs": [],
      "source": [
        "pad_token = 0\n",
        "sos_token = 1\n",
        "eos_token = 2\n",
        "\n",
        "word2index = {}\n",
        "word2count = {}\n",
        "index2word = {pad_token:'PAD', sos_token:'SOS', eos_token : 'EOS'}\n",
        "numword = 3\n",
        "\n",
        "for sent in questions:\n",
        "    for word in sent:\n",
        "        if word not in word2index:\n",
        "            word2index[word] = numword\n",
        "            word2count[word] = 1\n",
        "            index2word[numword] = word\n",
        "            numword += 1\n",
        "        else:\n",
        "            word2count[word] += 1\n",
        "\n",
        "\n",
        "for sent in responses:\n",
        "    for word in sent:\n",
        "        if word not in word2index:\n",
        "            word2index[word] = numword\n",
        "            word2count[word] = 1\n",
        "            index2word[numword] = word\n",
        "            numword += 1\n",
        "        else:\n",
        "            word2count[word] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "uKTItf3LRNSJ"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "3NhfqDxvMH8S"
      },
      "outputs": [],
      "source": [
        "class SeqDataset(Dataset):\n",
        "    def __init__(self, questions, responses, word2index, word2count, index2word, n_words, max_len):\n",
        "        self.questions = questions\n",
        "        self.responses = responses\n",
        "        self.word2index = word2index\n",
        "        self.word2count = word2count\n",
        "        self.index2word = index2word\n",
        "        self.n_words = n_words\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.questions)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        q = self.questions[idx]\n",
        "        r = self.responses[idx]\n",
        "\n",
        "        qt = [sos_token] + [self.word2index[word] for word in q]\n",
        "        qt = pad_sequences([qt], maxlen=self.max_len-1, padding='post', value=pad_token)\n",
        "        \n",
        "        rt = [sos_token] + [self.word2index[word] for word in r]\n",
        "        rt = pad_sequences([rt], maxlen=self.max_len-1, padding='post', value=pad_token)\n",
        "        \n",
        "        qt = qt[0]\n",
        "        rt = rt[0]\n",
        "\n",
        "        qt = np.append(qt, eos_token)\n",
        "        rt = np.append(rt, eos_token)\n",
        "\n",
        "        qt = torch.tensor(qt, dtype=torch.long, device=device)\n",
        "        rt = torch.tensor(rt, dtype=torch.long, device=device)\n",
        "\n",
        "        return (qt, rt)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 30"
      ],
      "metadata": {
        "id": "izZVujxmNKr6"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "thnCAXFJSoob"
      },
      "outputs": [],
      "source": [
        "mydata = SeqDataset(questions=questions,\n",
        "                    responses=responses,\n",
        "                    word2index=word2index,\n",
        "                    word2count=word2count,\n",
        "                    index2word=index2word,\n",
        "                    n_words=numword,\n",
        "                    max_len=max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "3d3A-gFWmGd2"
      },
      "outputs": [],
      "source": [
        "batch_size = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KU6Fn2EKJ6kH",
        "outputId": "17addcfa-e20d-46e9-ab03-94cca0f389b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([   1,  219,  429,   97,   13, 2422,   79, 3145,  101, 3146,   18, 2847,\n",
              "          163, 2848,   20, 3147,  949,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    2], device='cuda:0'),\n",
              " tensor([    1,    18,   128,   158,    69, 29611,   983, 11382,   780,   158,\n",
              "          8794,    26, 29612,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     2],\n",
              "        device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "mydata[500]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "K-xYlXeVWrkN"
      },
      "outputs": [],
      "source": [
        "train_iterator = DataLoader(mydata, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "a9JU6iz8hZen"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, hidden_size, number_of_words, num_layers = 1):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = nn.Embedding(number_of_words, hidden_size, padding_idx=pad_token)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.gru = nn.GRU(input_size = hidden_size,\n",
        "                          hidden_size = hidden_size,\n",
        "                          num_layers = num_layers,\n",
        "                          dropout = 0.2,\n",
        "                          bidirectional = False)\n",
        "        \n",
        "    def forward(self, input_seq, hidden = None):\n",
        "        embedding = self.embedding(input_seq)\n",
        "        output, hidden_cell = self.gru(embedding, hidden)\n",
        "        return output, hidden_cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "bT1PPe8UjEG8"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, n_layers=1):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "        \n",
        "        self.embedding = nn.Embedding(output_size, hidden_size, padding_idx=pad_token)\n",
        "        self.embedding_dropout = nn.Dropout(dropout)\n",
        "        self.gru = nn.GRU(hidden_size,\n",
        "                          hidden_size,\n",
        "                          n_layers,\n",
        "                          dropout=0.1)\n",
        "\n",
        "        self.linear = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        \n",
        "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input_step)\n",
        "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
        "        prediction = self.linear(rnn_output)\n",
        "        return prediction, hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "bk9vJSIabETj"
      },
      "outputs": [],
      "source": [
        "def train_step(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, batch_size, max_len):\n",
        "\n",
        "    #print('input_variable', input_variable)\n",
        "    #print('input_variable', input_variable.shape)\n",
        "\n",
        "\n",
        "    #print('target_variable', target_variable)\n",
        "    #print('target_variable', target_variable.shape)\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_variable = input_variable.to(device)\n",
        "    target_variable = target_variable.to(device)\n",
        "\n",
        "    output_encoders,  hidden_encoders = encoder(input_variable)\n",
        "    input_decoders = torch.LongTensor([[sos_token for _ in range(batch_size)]])\n",
        "    input_decoders = input_decoders.to(device)\n",
        "\n",
        "    hidden_decoders = hidden_encoders[:decoder.n_layers]\n",
        "\n",
        "\n",
        "    teacher_forcing_ratio = 0.5\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        for t in range(max_len):\n",
        "            output_decoders, hidden_decoders = decoder(input_decoders, hidden_decoders, output_encoders)\n",
        "            input_decoders = target_variable[t].view(1, -1)\n",
        "            tar = target_variable[t]\n",
        "            loss = criterion(torch.squeeze(output_decoders), tar)\n",
        "\n",
        "    else:\n",
        "        for t in range(max_len):\n",
        "            output_decoders, hidden_decoders = decoder(input_decoders, hidden_decoders, output_encoders)\n",
        "            tar = target_variable[t]\n",
        "            output_decoders = torch.squeeze(output_decoders)\n",
        "            loss = criterion(torch.squeeze(output_decoders), tar)\n",
        "            top1 = F.softmax(output_decoders)\n",
        "            top1 = top1.argmax(1)\n",
        "            input_decoders = top1.view(1, -1)\n",
        "\n",
        "\n",
        "    loss.backward()\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBRqflybdsVi",
        "outputId": "1b84a9ef-0750-4382-b289-946110608749"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building optimizers ...\n"
          ]
        }
      ],
      "source": [
        "hidden_size = 128\n",
        "encoder_n_layers = 3\n",
        "decoder_n_layers = 3\n",
        "dropout = 0.1\n",
        "checkpoint_iter = 10000\n",
        "\n",
        "start_iteration = 1\n",
        "print_loss = 0\n",
        "\n",
        "encoder = Encoder(hidden_size=hidden_size, number_of_words=numword, num_layers=encoder_n_layers)\n",
        "decoder = Decoder(hidden_size=hidden_size, output_size=numword, n_layers=decoder_n_layers)\n",
        "encoder = encoder.to(device)\n",
        "decoder = decoder.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "learning_rate = 0.001\n",
        "decoder_learning_rate = 2.0\n",
        "n_iteration = 10000\n",
        "print_every = 1000\n",
        "save_every = 5000\n",
        "path_save = './models/'\n",
        "\n",
        "encoder.train()\n",
        "decoder.train()\n",
        "\n",
        "print('Building optimizers ...')\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "MQBofpfbsXfi"
      },
      "outputs": [],
      "source": [
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfZRAAtxTWEG",
        "outputId": "e878aaf0-1c70-41e2-dcf9-0a46551f6fd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/10 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:40: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            " 10%|█         | 1/10 [00:24<03:36, 24.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "end of 0 epoh\n",
            "loss_avg at 624 is: 3.126020908355713\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [00:48<03:13, 24.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "end of 1 epoh\n",
            "loss_avg at 624 is: 2.9536900520324707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [01:12<02:48, 24.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "end of 2 epoh\n",
            "loss_avg at 624 is: 2.9283530712127686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [01:36<02:24, 24.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "end of 3 epoh\n",
            "loss_avg at 624 is: 2.877788543701172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [02:00<01:59, 23.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "end of 4 epoh\n",
            "loss_avg at 624 is: 2.843484878540039\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [02:23<01:35, 23.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "end of 5 epoh\n",
            "loss_avg at 624 is: 2.8436455726623535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [02:47<01:11, 23.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "end of 6 epoh\n",
            "loss_avg at 624 is: 2.828920841217041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [03:11<00:47, 23.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "end of 7 epoh\n",
            "loss_avg at 624 is: 2.824098587036133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [03:35<00:23, 23.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "end of 8 epoh\n",
            "loss_avg at 624 is: 2.8136589527130127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [03:59<00:00, 23.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "end of 9 epoh\n",
            "loss_avg at 624 is: 2.817549228668213\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "num_epoh = 10\n",
        "all_iter = 0\n",
        "\n",
        "for ep in tqdm.tqdm(range(num_epoh)):\n",
        "#for ep in range(num_epoh):\n",
        "    for iteration, batch in enumerate(train_iterator):\n",
        "        loss = train_step(batch[0].transpose(0, 1), batch[1].transpose(0, 1), encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, batch_size, max_len)\n",
        "        print_loss += loss\n",
        "        all_iter += 1\n",
        "\n",
        "    print_loss_avg = print_loss / all_iter\n",
        "    print(f'end of {ep} epoh')\n",
        "    print(f'loss_avg at {iteration} is: {print_loss_avg}')\n",
        "    print_loss = 0\n",
        "    all_iter = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "DEXSbbDWsauB"
      },
      "outputs": [],
      "source": [
        "sub_smp = df_filtred.sample(5)\n",
        "sent_q = sub_smp['question'].tolist()\n",
        "sent_a = sub_smp['responses'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "o201O2WUPIwT",
        "outputId": "53494d60-277e-4c7a-9264-90a8a8f73884"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'как в кратчайшие сроки научиться садиться на ...шпагат ? ))...'"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ],
      "source": [
        "sent_q[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "QKeGivXvyDD_"
      },
      "outputs": [],
      "source": [
        "def predict_answer(encoder, decoder, input_sentence, word2index, max_len, index2word):\n",
        "    input_sentence = preprocessing_sentence(input_sentence)\n",
        "    res_input_sentence = list()\n",
        "    for word in input_sentence:\n",
        "        if word in word2index:\n",
        "            res_input_sentence.append(word)\n",
        "    print(res_input_sentence)\n",
        "    sent = [sos_token] + [word2index[word] for word in res_input_sentence]\n",
        "    sent = pad_sequences([sent], maxlen=max_len-1, padding='post', value=pad_token)\n",
        "    sent = sent[0]\n",
        "    sent = np.append(sent, eos_token)\n",
        "    print(sent)\n",
        "    sent = torch.tensor([sent], dtype=torch.long, device=device)\n",
        "    sent = sent.transpose(0, 1)\n",
        "    input_batch = sent.to(device)\n",
        "\n",
        "    output_encoder, hidden_encoder = encoder(input_batch)\n",
        "    hidden_decoder = hidden_encoder[:decoder.n_layers]\n",
        "    input_decoder = torch.LongTensor([[sos_token for _ in range(1)]]).to(device)\n",
        "\n",
        "    all_tokens = torch.zeros([0], device=device, dtype = torch.long)\n",
        "\n",
        "    for _ in range(max_len):\n",
        "            output_decoder, hidden_decoder = decoder(input_decoder, hidden_decoder, output_encoder)\n",
        "            output_decoder = torch.squeeze(output_decoder)\n",
        "            output_decoder = F.softmax(output_decoder)\n",
        "            output_index = torch.argmax(output_decoder)\n",
        "            output_index = torch.unsqueeze(output_index, 0)\n",
        "            all_tokens = torch.cat((all_tokens, output_index), dim = 0)\n",
        "            input_decoder = torch.unsqueeze(output_index, 0)\n",
        "\n",
        "    words_decoder = [index2word[index.item()] for index in all_tokens]\n",
        "\n",
        "    print(words_decoder)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIf_HEWmyfdd",
        "outputId": "29395f24-bb4c-4c83-8c6d-7c9bb1c1283a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['как', 'в', 'кратчайшие', 'сроки', 'научиться', 'садиться', 'на', 'шпагат']\n",
            "[    1    16    20 25104 25105   259 25106    18 16260     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     2]\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ],
      "source": [
        "predict_answer(encoder, decoder, 'как в кратчайшие сроки научиться садиться на ...шпагат', word2index, max_len, index2word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H01BfKBezTEC"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "ya_project.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}